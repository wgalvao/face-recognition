# Guia de Fine-Tuning para Face Recognition

Este guia apresenta um passo a passo completo para realizar fine-tuning de modelos pr√©-treinados de face recognition em novos datasets usando o script `finetune.py`.

## üìã √çndice

1. [Vis√£o Geral](#vis√£o-geral)
2. [Estrat√©gias de Fine-Tuning](#estrat√©gias-de-fine-tuning)
3. [Pr√©-requisitos](#pr√©-requisitos)
4. [Prepara√ß√£o do Dataset](#prepara√ß√£o-do-dataset)
5. [Executando o Fine-Tuning](#executando-o-fine-tuning)
6. [Monitoramento e M√©tricas](#monitoramento-e-m√©tricas)
7. [Salvando e Carregando Modelos](#salvando-e-carregando-modelos)
8. [Troubleshooting](#troubleshooting)

---

## üéØ Vis√£o Geral

O fine-tuning permite adaptar modelos pr√©-treinados em VGGFace2 (validados no LFW) para novos datasets espec√≠ficos. O script oferece 3 estrat√©gias diferentes de fine-tuning, cada uma com suas vantagens e casos de uso.

### Estrutura do Processo

```
Modelo Pr√©-treinado (VGGFace2)
    ‚Üì
Fine-tuning no Novo Dataset
    ‚Üì
Modelo Fine-tuned Salvo
```

---

## üé® Estrat√©gias de Fine-Tuning

### 1. FULL_FINETUNE (Fine-tuning Completo)

**Descri√ß√£o:** Todos os par√¢metros do modelo (backbone + classification head) s√£o atualizados durante o treinamento, por√©m com learning rates reduzidos para preservar os conhecimentos pr√©-treinados.

**Vantagens:**
- M√°xima flexibilidade para adapta√ß√£o ao novo dataset
- Melhor para datasets grandes e diversos
- Permite ajustes finos em todas as camadas

**Desvantagens:**
- Requer mais recursos computacionais
- Risco de overfitting em datasets pequenos
- Necessita mais √©pocas de treinamento

**Learning Rates Padr√£o:**
- Backbone: `0.01` (10x menor que treinamento do zero)
- Head: `0.1`

**Recomendado para:**
- Datasets com mais de 10.000 imagens
- Quando o novo dataset √© similar ao dataset de pr√©-treinamento
- Quando h√° recursos computacionais suficientes

---

### 2. HEAD_ONLY (Apenas Classification Head)

**Descri√ß√£o:** O backbone do modelo √© completamente congelado (par√¢metros fixos), e apenas o classification head √© treinado para as novas classes.

**Vantagens:**
- Muito r√°pido de treinar
- Baixo risco de overfitting
- Ideal para datasets pequenos
- Preserva completamente os features aprendidos no pr√©-treinamento

**Desvantagens:**
- Limita a capacidade de adapta√ß√£o ao novo dataset
- N√£o aproveita ajustes espec√≠ficos do backbone

**Learning Rates Padr√£o:**
- Backbone: `0.0` (congelado)
- Head: `0.1`

**Recomendado para:**
- Datasets com menos de 5.000 imagens
- Quando o dataset √© muito similar ao de pr√©-treinamento
- Quando h√° limita√ß√µes de tempo/computa√ß√£o
- Transfer learning r√°pido

---

### 3. PROGRESSIVE (Descongelamento Progressivo)

**Descri√ß√£o:** Treinamento em 3 fases progressivas:
1. **Fase 1 (0-33% √©pocas):** Apenas classification head treinado
2. **Fase 2 (33-66% √©pocas):** Descongela layers finais do backbone
3. **Fase 3 (66-100% √©pocas):** Descongela todo o backbone

**Vantagens:**
- Equil√≠brio entre adapta√ß√£o e preserva√ß√£o de conhecimento
- Aprendizado gradual e est√°vel
- Bom para datasets m√©dios
- Reduz risco de overfitting inicial

**Desvantagens:**
- Mais complexo de configurar
- Pode ser mais lento que HEAD_ONLY

**Learning Rates Padr√£o:**
- Backbone: `0.005` (quando descongelado)
- Head: `0.1`

**Recomendado para:**
- Datasets com 5.000 - 10.000 imagens
- Quando h√° tempo suficiente para treinamento
- Quando precisa de melhor adapta√ß√£o que HEAD_ONLY mas com menos risco que FULL_FINETUNE

---

## üì¶ Pr√©-requisitos

### 1. Ambiente Python

Certifique-se de ter as depend√™ncias instaladas:

```bash
pip install -r requirements.txt
```

### 2. Modelo Pr√©-treinado

Voc√™ precisa de um checkpoint do modelo pr√©-treinado. O modelo deve ter sido treinado em VGGFace2 e validado no LFW.

**Estrutura esperada do checkpoint:**
```python
{
    'model': state_dict,           # Pesos do backbone
    'epoch': int,                  # √âpoca final
    'optimizer': state_dict,       # Estado do otimizador (opcional)
    'lr_scheduler': state_dict,    # Estado do scheduler (opcional)
    'args': namespace              # Argumentos do treinamento (opcional)
}
```

### 3. Dataset Preparado

O dataset deve estar organizado da seguinte forma:

```
/dados/datasets/aligned_112x112/vggface2_dataset_all_splits_merged/
‚îú‚îÄ‚îÄ person_001/
‚îÇ   ‚îú‚îÄ‚îÄ image001.jpg
‚îÇ   ‚îú‚îÄ‚îÄ image002.jpg
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ person_002/
‚îÇ   ‚îú‚îÄ‚îÄ image001.jpg
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ ...
```

**Requisitos:**
- Cada pasta representa uma identidade/classe diferente
- Imagens devem estar alinhadas e redimensionadas (recomendado 112x112)
- Formatos suportados: `.jpg`, `.jpeg`, `.png`

---

## üìÅ Prepara√ß√£o do Dataset

### 1. Verificar Estrutura

```bash
# Verificar n√∫mero de classes
ls -d /dados/datasets/aligned_112x112/vggface2_dataset_all_splits_merged/* | wc -l

# Verificar n√∫mero total de imagens
find /dados/datasets/aligned_112x112/vggface2_dataset_all_splits_merged/ -type f \( -name "*.jpg" -o -name "*.jpeg" -o -name "*.png" \) | wc -l
```

### 2. Estat√≠sticas do Dataset

O script contar√° automaticamente:
- N√∫mero de classes (identidades)
- N√∫mero de imagens por classe
- Total de imagens

---

## üöÄ Executando o Fine-Tuning

### Comando B√°sico

```bash
python finetune.py \
    --pretrained-checkpoint weights/mobilenetv3_large_MCP_best.ckpt \
    --root /dados/datasets/aligned_112x112/vggface2_dataset_all_splits_merged/ \
    --network mobilenetv3_large \
    --strategy FULL_FINETUNE \
    --classifier MCP \
    --epochs 20 \
    --batch-size 64
```

### Exemplos por Estrat√©gia

#### Exemplo 1: FULL_FINETUNE (Fine-tuning Completo)

```bash
python finetune.py \
    --pretrained-checkpoint weights/mobilenetv3_large_MCP_best.ckpt \
    --root /dados/datasets/aligned_112x112/vggface2_dataset_all_splits_merged/ \
    --network mobilenetv3_large \
    --strategy FULL_FINETUNE \
    --classifier MCP \
    --epochs 25 \
    --batch-size 64 \
    --lr-backbone 0.01 \
    --lr-head 0.1 \
    --lr-scheduler MultiStepLR \
    --milestones 15 20 \
    --gamma 0.1 \
    --save-path weights/finetuned_full \
    --val-dataset lfw \
    --val-root data/lfw/val
```

#### Exemplo 2: HEAD_ONLY (Apenas Head)

```bash
python finetune.py \
    --pretrained-checkpoint weights/mobilenetv3_large_MCP_best.ckpt \
    --root /dados/datasets/aligned_112x112/vggface2_dataset_all_splits_merged/ \
    --network mobilenetv3_large \
    --strategy HEAD_ONLY \
    --classifier MCP \
    --epochs 10 \
    --batch-size 128 \
    --lr-head 0.1 \
    --save-path weights/finetuned_head_only \
    --val-dataset lfw \
    --val-root data/lfw/val
```

#### Exemplo 3: PROGRESSIVE (Progressivo)

```bash
python finetune.py \
    --pretrained-checkpoint weights/mobilenetv3_large_MCP_best.ckpt \
    --root /dados/datasets/aligned_112x112/vggface2_dataset_all_splits_merged/ \
    --network mobilenetv3_large \
    --strategy PROGRESSIVE \
    --classifier MCP \
    --epochs 30 \
    --batch-size 64 \
    --lr-backbone 0.005 \
    --lr-head 0.1 \
    --lr-scheduler MultiStepLR \
    --milestones 10 20 25 \
    --gamma 0.1 \
    --save-path weights/finetuned_progressive \
    --val-dataset lfw \
    --val-root data/lfw/val
```

### Par√¢metros Principais

| Par√¢metro | Descri√ß√£o | Padr√£o | Obrigat√≥rio |
|-----------|-----------|--------|-------------|
| `--pretrained-checkpoint` | Caminho do checkpoint pr√©-treinado | - | ‚úÖ Sim |
| `--root` | Diret√≥rio do novo dataset | - | ‚úÖ Sim |
| `--network` | Arquitetura do modelo | - | ‚úÖ Sim |
| `--strategy` | Estrat√©gia de fine-tuning | `FULL_FINETUNE` | N√£o |
| `--classifier` | Tipo de classificador | `MCP` | N√£o |
| `--epochs` | N√∫mero de √©pocas | `20` | N√£o |
| `--batch-size` | Tamanho do batch | `64` | N√£o |
| `--lr-backbone` | Learning rate do backbone | Auto | N√£o |
| `--lr-head` | Learning rate do head | `0.1` | N√£o |
| `--save-path` | Diret√≥rio para salvar modelos | `weights/finetuned` | N√£o |
| `--val-dataset` | Dataset de valida√ß√£o | `lfw` | N√£o |
| `--val-root` | Diret√≥rio do dataset de valida√ß√£o | `data/lfw/val` | N√£o |

---

## üìä Monitoramento e M√©tricas

### Durante o Treinamento

O script exibe informa√ß√µes a cada √©poca:

```
Epoch: [1/20][00100/00500] Loss: 2.345, Accuracy: 45.23%, LR: 0.01000 Time: 0.123s
```

### M√©tricas de Valida√ß√£o

A cada √©poca, o modelo √© avaliado no conjunto de valida√ß√£o (LFW ou CelebA):

```
==================================================
EPOCH 1 VALIDATION METRICS
==================================================

Validation Metrics (Threshold=0.35):
  Precision: 0.8234
  Recall:    0.7891
  F1-Score:  0.8059
  Accuracy:  0.8123

ROC Metrics:
  AUC: 0.9123
  EER: 0.0821

Internal validation accuracy: 0.8456
==================================================
```

### Arquivos de Sa√≠da

Os resultados s√£o salvos em:

```
weights/finetuned/
‚îú‚îÄ‚îÄ mobilenetv3_large_MCP_finetuned_full_last.ckpt      # √öltimo checkpoint
‚îú‚îÄ‚îÄ mobilenetv3_large_MCP_finetuned_full_best.ckpt      # Melhor checkpoint
‚îî‚îÄ‚îÄ metrics/
    ‚îú‚îÄ‚îÄ epoch_1/
    ‚îÇ   ‚îú‚îÄ‚îÄ lfw_roc_curve.png
    ‚îÇ   ‚îî‚îÄ‚îÄ lfw_confusion_matrix.png
    ‚îú‚îÄ‚îÄ epoch_2/
    ‚îÇ   ‚îî‚îÄ‚îÄ ...
    ‚îî‚îÄ‚îÄ final_evaluation/
        ‚îú‚îÄ‚îÄ lfw_roc_curve.png
        ‚îî‚îÄ‚îÄ lfw_confusion_matrix.png
```

### Early Stopping

O script inclui early stopping autom√°tico que para o treinamento se n√£o houver melhoria por 10 √©pocas consecutivas.

---

## üíæ Salvando e Carregando Modelos

### Estrutura do Checkpoint Salvo

```python
{
    'epoch': int,                          # √âpoca atual
    'model': state_dict,                   # Pesos do backbone
    'classification_head': state_dict,     # Pesos do classification head
    'optimizer': state_dict,               # Estado do otimizador
    'lr_scheduler': state_dict,            # Estado do scheduler
    'num_classes': int,                    # N√∫mero de classes do novo dataset
    'strategy': str,                       # Estrat√©gia usada
    'pretrained_checkpoint': str,          # Caminho do checkpoint original
    'args': namespace                      # Argumentos do fine-tuning
}
```

### Carregando um Modelo Fine-tuned

```python
import torch
from inference import get_network, load_model

# Caminho do checkpoint fine-tuned
checkpoint_path = "weights/finetuned/mobilenetv3_large_MCP_finetuned_full_best.ckpt"

# Carregar checkpoint
checkpoint = torch.load(checkpoint_path, map_location='cpu')

# Obter n√∫mero de classes
num_classes = checkpoint['num_classes']
strategy = checkpoint['strategy']

print(f"Modelo fine-tuned com estrat√©gia: {strategy}")
print(f"N√∫mero de classes: {num_classes}")

# Carregar modelo usando a fun√ß√£o existente (pode precisar ajuste)
model = get_network('mobilenetv3_large')(embedding_dim=512)
model.load_state_dict(checkpoint['model'])

# Carregar classification head
from utils.metrics import MarginCosineProduct
classification_head = MarginCosineProduct(512, num_classes)
classification_head.load_state_dict(checkpoint['classification_head'])
```

### Usando o Modelo para Infer√™ncia

```python
import torch
from inference import extract_features

# Carregar modelo e head
model.eval()
classification_head.eval()

# Extrair features
with torch.no_grad():
    embeddings = model(images)  # (batch_size, 512)
    outputs, _ = classification_head(embeddings, labels)  # Para treinamento
    # ou apenas embeddings para compara√ß√£o de similaridade
```

---

## üîß Configura√ß√µes Avan√ßadas

### Learning Rates Customizados

Voc√™ pode especificar learning rates personalizados:

```bash
python finetune.py \
    --pretrained-checkpoint weights/model.ckpt \
    --root /path/to/dataset/ \
    --network mobilenetv3_large \
    --strategy FULL_FINETUNE \
    --lr-backbone 0.005 \      # LR menor para backbone
    --lr-head 0.05             # LR menor para head
```

### Schedulers de Learning Rate

#### MultiStepLR (Recomendado)

```bash
--lr-scheduler MultiStepLR \
--milestones 10 15 20 \
--gamma 0.1
```

Reduz o LR em 10x nas √©pocas 10, 15 e 20.

#### StepLR

```bash
--lr-scheduler StepLR \
--step-size 5 \
--gamma 0.5
```

Reduz o LR pela metade a cada 5 √©pocas.

### Valida√ß√£o com RetinaFace

Para valida√ß√£o mais rigorosa, use RetinaFace:

```bash
--use-retinaface-validation \
--no-face-policy exclude \
--retinaface-conf-threshold 0.5
```

### Treinamento Distribu√≠do (Multi-GPU)

```bash
torchrun --nproc_per_node=4 finetune.py \
    --pretrained-checkpoint weights/model.ckpt \
    --root /path/to/dataset/ \
    --network mobilenetv3_large \
    --strategy FULL_FINETUNE \
    --batch-size 64
```

---

## üêõ Troubleshooting

### Problema: "Checkpoint not found"

**Solu√ß√£o:** Verifique o caminho do checkpoint:

```bash
ls -lh weights/mobilenetv3_large_MCP_best.ckpt
```

### Problema: "Dataset directory does not exist"

**Solu√ß√£o:** Verifique se o caminho do dataset est√° correto:

```bash
ls /dados/datasets/aligned_112x112/vggface2_dataset_all_splits_merged/
```

### Problema: "Out of memory" (OOM)

**Solu√ß√µes:**
1. Reduza o batch size:
   ```bash
   --batch-size 32  # ou menor
   ```
2. Use estrat√©gia HEAD_ONLY (menos par√¢metros trein√°veis)
3. Reduza o n√∫mero de workers:
   ```bash
   --num-workers 4
   ```

### Problema: Accuracy n√£o melhora

**Solu√ß√µes:**
1. Verifique se o learning rate est√° adequado:
   - Muito alto: reduce o LR
   - Muito baixo: aumente o LR
2. Tente outra estrat√©gia (ex: FULL_FINETUNE se estava usando HEAD_ONLY)
3. Aumente o n√∫mero de √©pocas
4. Verifique a qualidade do dataset

### Problema: Overfitting

**Solu√ß√µes:**
1. Use estrat√©gia HEAD_ONLY
2. Aumente weight decay:
   ```bash
   --weight-decay 1e-3
   ```
3. Use data augmentation (j√° inclu√≠do: random horizontal flip)
4. Reduza o n√∫mero de √©pocas ou use early stopping mais agressivo

### Problema: Modelo n√£o est√° aprendendo novas classes

**Solu√ß√µes:**
1. Verifique se o classification head foi criado corretamente (n√∫mero de classes)
2. Use learning rate maior para o head:
   ```bash
   --lr-head 0.2
   ```
3. Verifique se o dataset est√° bem balanceado

---

## üìà Boas Pr√°ticas

### 1. Escolha da Estrat√©gia

- **Dataset pequeno (< 5K imagens):** HEAD_ONLY
- **Dataset m√©dio (5K - 10K):** PROGRESSIVE
- **Dataset grande (> 10K):** FULL_FINETUNE

### 2. Learning Rates

- Comece com os valores padr√£o
- Se n√£o houver melhoria ap√≥s 5 √©pocas, reduza o LR
- Se houver instabilidade (loss muito alto), reduza o LR

### 3. Monitoramento

- Acompanhe tanto a accuracy interna quanto a similaridade no LFW
- Se a similaridade no LFW diminuir muito, pode estar havendo overfitting
- Use os gr√°ficos ROC salvos para an√°lise detalhada

### 4. Checkpoints

- Sempre salve o melhor modelo (`_best.ckpt`)
- Mantenha tamb√©m o √∫ltimo checkpoint para continuar treinamento
- Documente qual estrat√©gia e hiperpar√¢metros foram usados

---

## üìö Refer√™ncias e Recursos

- [Documenta√ß√£o do PyTorch](https://pytorch.org/docs/stable/index.html)
- [Transfer Learning Guide](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)
- Artigo: "How transferable are features in deep neural networks?" (Yosinski et al., 2014)

---

## üìù Exemplo Completo

Aqui est√° um exemplo completo de fine-tuning end-to-end:

```bash
# 1. Verificar dataset
python -c "from utils.dataset import ImageFolder; ds = ImageFolder('/dados/datasets/aligned_112x112/vggface2_dataset_all_splits_merged/'); print(f'Classes: {len(set([l for _, l in ds.samples]))}, Images: {len(ds)}')"

# 2. Fine-tuning com FULL_FINETUNE
python finetune.py \
    --pretrained-checkpoint weights/mobilenetv3_large_MCP_best.ckpt \
    --root /dados/datasets/aligned_112x112/vggface2_dataset_all_splits_merged/ \
    --network mobilenetv3_large \
    --strategy FULL_FINETUNE \
    --classifier MCP \
    --epochs 20 \
    --batch-size 64 \
    --lr-backbone 0.01 \
    --lr-head 0.1 \
    --lr-scheduler MultiStepLR \
    --milestones 10 15 \
    --gamma 0.1 \
    --save-path weights/finetuned_mydataset \
    --val-dataset lfw \
    --val-root data/lfw/val \
    --print-freq 50

# 3. Avaliar modelo fine-tuned
python evaluate.py \
    --model-path weights/finetuned_mydataset/mobilenetv3_large_MCP_finetuned_full_best.ckpt \
    --network mobilenetv3_large \
    --val-dataset lfw \
    --val-root data/lfw/val
```

---

**√öltima atualiza√ß√£o:** 2024

**Autor:** Sistema de Fine-tuning para Face Recognition

---

## üéì Gloss√°rio

- **Backbone:** Parte do modelo respons√°vel por extrair features (ex: MobileNet, SphereNet)
- **Classification Head:** Camada final que classifica os embeddings em classes
- **Checkpoint:** Arquivo contendo os pesos do modelo em um determinado momento do treinamento
- **Embedding:** Representa√ß√£o vetorial de uma face (normalmente 512 dimens√µes)
- **Fine-tuning:** Processo de ajustar um modelo pr√©-treinado para um novo dataset
- **Learning Rate:** Taxa de aprendizado, controla o tamanho dos ajustes nos pesos
- **Overfitting:** Quando o modelo memoriza o dataset de treino mas n√£o generaliza bem
- **State Dict:** Dicion√°rio contendo os pesos de um modelo PyTorch
